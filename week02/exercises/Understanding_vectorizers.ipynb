{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e4aa57f",
   "metadata": {},
   "source": [
    "# Understanding vectorizers\n",
    "\n",
    "In the following code examples, we will experiment with vectorizers to understand a bit better how they work. Feel free to adjust the code, and try things out yourself.\n",
    "\n",
    "For now, we will practice with `sklearn`'s vectorizers. however, packages such as `gensim` offer their own build in functionality to vectorize the data. We will start working with `gensim` in week 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29eb18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02d45caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0372eb2",
   "metadata": {},
   "source": [
    "## Example 1: Inspect the output of a vectorizer in a dense format\n",
    "\n",
    "The following code cell will fit and transform three documents using a `Count`-based vectorizer. Next, the output is transformed to a *dense* matrix, and printed. \n",
    "\n",
    "1. Do you understand the output?\n",
    "2. Is it smart to transform output to a dense format? What will happen if you work with millions of documents, rather than 3 short sentences?\n",
    "3. what happens if you replace `CountVectorizer()` for `TfidfVectorizer()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fe0a32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"hello students!\", \"how are you today?\", \"what?\", \"hello hello everybody\"]\n",
    "#vect = CountVectorizer()\n",
    "vect = TfidfVectorizer()# initialize the vectorizer\n",
    "X = vect.fit_transform(texts) #fit the vectorizer and transform the documents in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a8609a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   are  everybody     hello  how  students  today  what  you\n",
      "0  0.0   0.000000  0.619130  0.0  0.785288    0.0   0.0  0.0\n",
      "1  0.5   0.000000  0.000000  0.5  0.000000    0.5   0.0  0.5\n",
      "2  0.0   0.000000  0.000000  0.0  0.000000    0.0   1.0  0.0\n",
      "3  0.0   0.535566  0.844493  0.0  0.000000    0.0   0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X.A, columns=vect.get_feature_names_out()).to_string())\n",
    "df = pd.DataFrame(X.toarray().transpose(), index = vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c0c0c5",
   "metadata": {},
   "source": [
    "## Example 2: Inspect the output of a vectorizer in a sparse format\n",
    "\n",
    "Internally, `sklearn` represents the data in a *sparse* format, as this is computationally more efficient, and less memory is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea857d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"hello students!\", \"how are you today?\", \"what?\", \"hello hello everybody\"]\n",
    "count_vec = CountVectorizer() #initilize the vectorizer\n",
    "count_vec_fit = count_vec.fit_transform(texts) #fit the vectorizer and transform the documents in one go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03354120",
   "metadata": {},
   "source": [
    "    1.Inspect the shape of transformed texts. We can see that we have a 4x8 sparse matrix, meaning that we have 4 \n",
    "    rows (=documents) and 8 unique tokens (=words, numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe603bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x8 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd6f01",
   "metadata": {},
   "source": [
    "    2.Get the feature names. This will return the tokens that are in the vocabulary of the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a925f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['are', 'everybody', 'hello', 'how', 'students', 'today', 'what',\n",
       "       'you'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2c6f3",
   "metadata": {},
   "source": [
    "    3. Represent the token's mapping to it's id values. The numbers do *not* represent the count of the words but the position of the words in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0937869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 2,\n",
       " 'students': 4,\n",
       " 'how': 3,\n",
       " 'are': 0,\n",
       " 'you': 7,\n",
       " 'today': 5,\n",
       " 'what': 6,\n",
       " 'everybody': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.vocabulary_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b768f3b",
   "metadata": {},
   "source": [
    "    4. Get sparse representation on document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62d39871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current document: hello students!\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "\n",
      "Current document: how are you today?\n",
      "  (0, 3)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 5)\t1\n",
      "\n",
      "Current document: what?\n",
      "  (0, 6)\t1\n",
      "\n",
      "Current document: hello hello everybody\n",
      "  (0, 2)\t2\n",
      "  (0, 1)\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, document in zip(count_vec_fit, texts):\n",
    "    print(f\"Current document: {document}\")\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4a49e",
   "metadata": {},
   "source": [
    "a. Do you understand the output printed above?  \n",
    "b. What happens if you change the `count` to a `tfidf` vectorizer?  \n",
    "c. Adjust the code using the slides of [this week](https://github.com/uva-cw-ccs2/2223s2/blob/master/week03/week03-lecture.pdf). More specifically, try removing stopwords, pruning and see how your results are affected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02771f7f",
   "metadata": {},
   "source": [
    "    5. Get some final describtives about the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d845b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero elements: 9\n",
      "Total number of elements: 32\n",
      "Sparsity: 0.6875\n"
     ]
    }
   ],
   "source": [
    "nonzero = df.astype(bool).sum(axis=0)\n",
    "print(\"Number of non-zero elements:\", nonzero.sum())\n",
    "print(\"Total number of elements:\", count_vec_fit.shape[0] * count_vec_fit.shape[1])\n",
    "\n",
    "# compute the sparsity of the matrix: w the proportion of zero elements in the matrix\n",
    "print(\"Sparsity:\", 1 - count_vec_fit.sum() / (count_vec_fit.shape[0] * count_vec_fit.shape[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
